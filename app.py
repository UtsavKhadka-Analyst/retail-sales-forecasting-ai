import streamlit as st
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from openai import OpenAI
from datetime import datetime
import io

# ==========================================
# 1. PAGE CONFIGURATION & STYLING
# ==========================================
st.set_page_config(
    page_title="Retail AI Analyst",
    page_icon="üõçÔ∏è",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Custom CSS for a professional look
st.markdown("""
    <style>
    .main { background-color: #f8f9fa; }
    .stMetric {
        background-color: #ffffff;
        padding: 15px;
        border-radius: 10px;
        box-shadow: 1px 1px 4px rgba(0,0,0,0.1);
    }
    h1, h2, h3 { color: #2c3e50; }
    </style>
    """, unsafe_allow_html=True)

# ==========================================
# 2. DATA LOADING FUNCTIONS
# ==========================================
@st.cache_data
def load_demo_data():
    """Loads files directly from the GitHub repo (Demo Mode)"""
    try:
        df_f = pd.read_csv("forecast_results.csv")
        df_a = pd.read_csv("anomalies.csv")
        with open("summary.md", "r") as f:
            txt = f.read()
        return df_f, df_a, txt
    except FileNotFoundError:
        return None, None, None

def load_uploaded_data(up_f, up_a, up_s):
    """Loads files uploaded by the user (Live Mode)"""
    try:
        df_f = pd.read_csv(up_f)
        df_a = pd.read_csv(up_a)
        txt = up_s.read().decode("utf-8")
        return df_f, df_a, txt
    except Exception as e:
        st.error(f"Error loading files: {e}")
        return None, None, None

# ==========================================
# 3. SIDEBAR CONFIGURATION
# ==========================================
with st.sidebar:
    st.image("https://cdn-icons-png.flaticon.com/512/3081/3081559.png", width=50)
    st.title("Settings")
    
    # Mode Switcher
    data_source = st.radio(
        "Data Source:", 
        ["Use Demo Data (GitHub)", "Upload My Own Data"],
        captions=["Pre-loaded Walmart Dataset", "Process new data via Colab first"]
    )
    
    st.divider()
    
    # OpenAI Key (Secure)
    st.subheader("ü§ñ AI Analyst Access")
    api_key = st.text_input("OpenAI API Key:", type="password", help="Required for the Chatbot tab")
    
    st.info("‚ÑπÔ∏è **Note:** This dashboard visualizes processed data. Heavy model training (LSTM) runs externally on Google Colab.")

# ==========================================
# 4. LOAD DATA BASED ON SELECTION
# ==========================================
if data_source == "Use Demo Data (GitHub)":
    forecast_df, anomalies_df, summary_context = load_demo_data()
    if forecast_df is None:
        st.error("‚ö†Ô∏è Demo files missing! Please ensure 'forecast_results.csv', 'anomalies.csv', and 'summary.md' are in your repo.")
        st.stop()
    else:
        st.success("‚úÖ Loaded Demo Data (Walmart Sales)")

else: # Upload Mode
    st.markdown("### üìÇ Upload Processed Files")
    st.caption("Upload the 3 files generated by your Colab Notebook.")
    col_u1, col_u2, col_u3 = st.columns(3)
    up_f = col_u1.file_uploader("Upload 'forecast_results.csv'", type="csv")
    up_a = col_u2.file_uploader("Upload 'anomalies.csv'", type="csv")
    up_s = col_u3.file_uploader("Upload 'summary.md'", type="md")
    
    if up_f and up_a and up_s:
        forecast_df, anomalies_df, summary_context = load_uploaded_data(up_f, up_a, up_s)
        st.success("‚úÖ Custom Data Loaded Successfully")
    else:
        st.info("üëã Waiting for uploads...")
        st.stop()

# Preprocessing Dates
forecast_df['Date'] = pd.to_datetime(forecast_df['Date'])
anomalies_df['Date'] = pd.to_datetime(anomalies_df['Date'])

# ==========================================
# 5. MAIN DASHBOARD UI
# ==========================================
st.title("üõçÔ∏è AI-Powered Retail Analytics Platform")
st.markdown("### Hybrid Forecasting (Prophet + LSTM) & Automated Anomaly Detection")

tab1, tab2, tab3 = st.tabs(["üìä Executive Dashboard", "üí¨ AI Business Analyst", "üì• Export Data"])

# --- TAB 1: VISUALIZATION ---
with tab1:
    # A. Metrics Row
    st.subheader("Key Performance Indicators")
    kpi1, kpi2, kpi3, kpi4 = st.columns(4)
    
    avg_sales = forecast_df['Hybrid'].mean()
    next_week = forecast_df['Hybrid'].iloc[0]
    peak_sales = forecast_df['Hybrid'].max()
    total_anoms = len(anomalies_df)
    
    kpi1.metric("Avg Projected Sales", f"${avg_sales:,.0f}", delta="12 Week Avg")
    kpi2.metric("Next Week Forecast", f"${next_week:,.0f}", delta="Immediate Demand")
    kpi3.metric("Peak Forecast", f"${peak_sales:,.0f}", delta="High Point")
    kpi4.metric("Anomalies Detected", f"{total_anoms}", delta="Attention Needed", delta_color="inverse")

    st.markdown("---")

    # B. Main Forecast Chart
    st.subheader("üìà Forecast Trends (Hybrid vs Individual Models)")
    
    fig = go.Figure()
    
    # 1. Prophet Line
    fig.add_trace(go.Scatter(
        x=forecast_df['Date'], y=forecast_df['Prophet'],
        mode='lines', name='Prophet (Seasonality)',
        line=dict(dash='dot', color='blue', width=1)
    ))
    
    # 2. LSTM Line
    fig.add_trace(go.Scatter(
        x=forecast_df['Date'], y=forecast_df['LSTM'],
        mode='lines', name='LSTM (Patterns)',
        line=dict(dash='dot', color='orange', width=1)
    ))
    
    # 3. Hybrid Line (The Winner)
    fig.add_trace(go.Scatter(
        x=forecast_df['Date'], y=forecast_df['Hybrid'],
        mode='lines+markers', name='Hybrid Final (Best)',
        line=dict(color='#E63946', width=3)
    ))

    # 4. Anomalies (Red X)
    fig.add_trace(go.Scatter(
        x=anomalies_df['Date'], y=anomalies_df['Weekly_Sales'],
        mode='markers', name='Anomaly',
        marker=dict(color='red', size=10, symbol='x')
    ))

    fig.update_layout(
        hovermode="x unified",
        height=500,
        legend=dict(orientation="h", y=1.02, x=1),
        margin=dict(l=20, r=20, t=50, b=20)
    )
    st.plotly_chart(fig, use_container_width=True)

# --- TAB 2: AI CHATBOT ---
with tab2:
    col_chat1, col_chat2 = st.columns([2, 1])
    
    with col_chat1:
        st.header("üí¨ Ask the AI Analyst")
        st.markdown("_Powered by RAG (Retrieval-Augmented Generation)_")
        
        if not api_key:
            st.warning("‚ö†Ô∏è Please enter your OpenAI API Key in the Sidebar to start chatting.")
        else:
            client = OpenAI(api_key=api_key)

            # Initialize Chat History
            if "messages" not in st.session_state:
                st.session_state.messages = [
                    {"role": "system", "content": f"You are a Senior Retail Data Analyst. Use the following report to answer user questions. Be concise and professional.\n\nREPORT CONTEXT:\n{summary_context}"}
                ]

            # Display Chat History
            for message in st.session_state.messages:
                if message["role"] != "system":
                    with st.chat_message(message["role"]):
                        st.markdown(message["content"])

            # User Input
            if prompt := st.chat_input("Ex: Why did sales spike in December?"):
                st.session_state.messages.append({"role": "user", "content": prompt})
                with st.chat_message("user"):
                    st.markdown(prompt)

                # Generate Response
                try:
                    with st.chat_message("assistant"):
                        stream = client.chat.completions.create(
                            model="gpt-3.5-turbo",
                            messages=[{"role": m["role"], "content": m["content"]} for m in st.session_state.messages],
                            stream=True,
                        )
                        response = st.write_stream(stream)
                    st.session_state.messages.append({"role": "assistant", "content": response})
                except Exception as e:
                    st.error(f"Error: {e}")

    with col_chat2:
        st.info("üí° **Suggested Questions:**")
        st.markdown("""
        * "Summarize the sales forecast for the next 12 weeks."
        * "What caused the detected anomalies?"
        * "Compare the Prophet and LSTM models."
        * "Is the general trend positive or negative?"
        """)
        with st.expander("View Raw Summary Data"):
            st.text(summary_context)

# --- TAB 3: EXPORT ---
with tab3:
    st.header("üì• Download Data")
    col_d1, col_d2 = st.columns(2)
    
    with col_d1:
        st.subheader("Forecast Data")
        csv_f = forecast_df.to_csv(index=False).encode('utf-8')
        st.download_button("Download Forecast CSV", data=csv_f, file_name="forecast_results.csv", mime="text/csv")
        st.dataframe(forecast_df.head())
        
    with col_d2:
        st.subheader("Anomaly Data")
        csv_a = anomalies_df.to_csv(index=False).encode('utf-8')
        st.download_button("Download Anomalies CSV", data=csv_a, file_name="anomalies.csv", mime="text/csv")
        st.dataframe(anomalies_df.head())
